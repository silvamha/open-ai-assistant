# AI Assistant Setup Guide

## Project Overview
This guide walks through creating a customizable AI assistant using OpenAI's Assistant API with vector search capabilities for conversation memory.

## Prerequisites
- Node.js (v20.11.1 or later)
- OpenAI API key
- Supabase account (free tier works fine)

## Step 1: Initial Setup
```bash
# Create project directory and initialize
mkdir your-assistant-app
cd your-assistant-app
npm init -y

# Install dependencies
npm install express cors dotenv openai @supabase/supabase-js
npm install --save-dev nodemon
```

## Step 2: Environment Setup
Create a `.env` file:
```env
OPENAI_API_KEY=your_openai_key
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_anon_key
```

## Step 3: Supabase Vector Database Setup
1. Create new Supabase project
2. Enable Vector extension in SQL Editor:
```sql
create extension if not exists vector;
```

3. Create chat embeddings table:
```sql
create table chat_embeddings (
  id bigint generated by default as identity primary key,
  content text,
  embedding vector(1536),
  metadata jsonb,
  thread_id text,
  created_at timestamp with time zone default timezone('utc'::text, now())
);
```

4. Create similarity search function:
```sql
create or replace function match_chat_messages (
  query_embedding vector(1536),
  match_threshold float,
  match_count int
)
returns table (
  id bigint,
  content text,
  metadata jsonb,
  thread_id text,
  similarity float
)
language plpgsql
as $$
begin
  return query
  select
    chat_embeddings.id,
    chat_embeddings.content,
    chat_embeddings.metadata,
    chat_embeddings.thread_id,
    1 - (chat_embeddings.embedding <=> query_embedding) as similarity
  from chat_embeddings
  where 1 - (chat_embeddings.embedding <=> query_embedding) > match_threshold
  order by chat_embeddings.embedding <=> query_embedding
  limit match_count;
end;
$$;
```

5. Disable RLS for development:
```sql
alter table chat_embeddings disable row level security;
```

## Step 4: Project Structure
```
your-assistant-app/
├── public/
│   ├── images/
│   ├── js/
│   │   └── chat.js
│   ├── styles.css
│   └── index.html
├── src/
│   ├── config/
│   │   ├── config.js
│   │   └── assistant-personality.js
│   ├── services/
│   │   ├── assistant.js
│   │   └── vector/
│   │       ├── config.js
│   │       └── service.js
│   ├── app.js
│   └── server.js
├── scripts/
│   └── embed-chats.js
├── .env
└── package.json
```

## Step 5: Assistant Personality
Create `src/config/assistant-personality.js` to define your assistant's character:
```javascript
module.exports = {
    name: "Your Assistant Name",
    instructions: `[Detailed personality and behavior instructions]`
};
```

## Step 6: Vector Service Setup
1. Create embedding script (`scripts/embed-chats.js`)
2. Test with sample messages:
```bash
node scripts/embed-chats.js
```

## Step 7: UI Customization
1. Modify `public/styles.css` for theme
2. Add assistant image (250x250px) to `public/images/`
3. Update HTML to reflect branding

## Business Implementation Tips
1. For English Schools:
   - Customize personality for language learning
   - Add specific vocabulary and grammar exercises
   - Include cultural context awareness
   - Support multiple languages

2. For Medical Offices:
   - Focus on appointment scheduling
   - Basic symptom triage
   - Medical form explanations
   - Multilingual support for diverse patients
   - HIPAA compliance considerations

## Monetization Strategies
1. Tiered Pricing:
   - Basic (appointment scheduling, FAQs)
   - Premium (full conversation memory, custom features)
   - Enterprise (multiple assistants, analytics)

2. Add-on Services:
   - Custom personality development
   - Training data integration
   - Analytics dashboard
   - Staff training

## Maintenance
1. Regularly update embeddings with new conversations
2. Monitor OpenAI API usage
3. Backup Supabase database
4. Update assistant instructions based on user feedback

## Security Considerations
1. Implement proper authentication
2. Enable RLS in production
3. Sanitize user inputs
4. Regular security audits
5. Data retention policies

Remember to test thoroughly in development before deploying to production!
